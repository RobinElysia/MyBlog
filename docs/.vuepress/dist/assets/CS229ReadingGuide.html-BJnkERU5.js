import{_ as a,c as i,b as l,e as n,w as e,j as r,a as m,i as o}from"./app-BPzQcCmO.js";const p="/assets/img/MachineLearning/Voyager3.jpg",u={};function d(f,t){const s=r("RouteLink");return m(),i("div",null,[t[28]||(t[28]=l("p",null,[l("img",{src:p,style:{display:"block",margin:"0 auto"}})],-1)),t[29]||(t[29]=l("h2",{id:"目录",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#目录"},[l("span",null,"目录")])],-1)),l("ul",null,[l("li",null,[n(s,{to:"/posts/CS229/cs229-notes1.html"},{default:e(()=>t[0]||(t[0]=[o("第一部分到第三部分")])),_:1,__:[0]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes2.html"},{default:e(()=>t[1]||(t[1]=[o("第四部分 生成学习算法")])),_:1,__:[1]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes3.html"},{default:e(()=>t[2]||(t[2]=[o("第五部分 支持向量机")])),_:1,__:[2]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes4.html"},{default:e(()=>t[3]||(t[3]=[o("第六部分 学习理论")])),_:1,__:[3]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes5.html"},{default:e(()=>t[4]||(t[4]=[o("第七部分 正则化与模型选择")])),_:1,__:[4]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes6.html"},{default:e(()=>t[5]||(t[5]=[o("感知器和大型边界分类器")])),_:1,__:[5]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes7a.html"},{default:e(()=>t[6]||(t[6]=[o("K 均值聚类算法")])),_:1,__:[6]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes7b.html"},{default:e(()=>t[7]||(t[7]=[o("混合高斯和期望最大化算法")])),_:1,__:[7]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes8.html"},{default:e(()=>t[8]||(t[8]=[o("第九部分 期望最大化算法")])),_:1,__:[8]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes9.html"},{default:e(()=>t[9]||(t[9]=[o("第十部分 因子分析")])),_:1,__:[9]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes10.html"},{default:e(()=>t[10]||(t[10]=[o("第十一部分 主成分分析")])),_:1,__:[10]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes11.html"},{default:e(()=>t[11]||(t[11]=[o("第十二部分 独立成分分析")])),_:1,__:[11]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes12.html"},{default:e(()=>t[12]||(t[12]=[o("第十三部分 强化学习和控制")])),_:1,__:[12]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes13.html"},{default:e(()=>t[13]||(t[13]=[o("第十四部分 线性二次调节，微分动态规划，线性二次高斯分布")])),_:1,__:[13]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-deep_learning.html"},{default:e(()=>t[14]||(t[14]=[o("深度学习")])),_:1,__:[14]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-BP.html"},{default:e(()=>t[15]||(t[15]=[o("反向传播")])),_:1,__:[15]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-dt.html"},{default:e(()=>t[16]||(t[16]=[o("决策树")])),_:1,__:[16]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-ensemble.html"},{default:e(()=>t[17]||(t[17]=[o("集成学习")])),_:1,__:[17]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-cvxopt.html"},{default:e(()=>t[18]||(t[18]=[o("凸优化1")])),_:1,__:[18]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-cvxopt2.html"},{default:e(()=>t[19]||(t[19]=[o("凸优化2")])),_:1,__:[19]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-hmm.html"},{default:e(()=>t[20]||(t[20]=[o("隐马尔可夫模型基础")])),_:1,__:[20]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-gaussians.html"},{default:e(()=>t[21]||(t[21]=[o("多元高斯分布")])),_:1,__:[21]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-notes-more_on_gaussians.html"},{default:e(()=>t[22]||(t[22]=[o("更多关于多元高斯分布")])),_:1,__:[22]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-gaussian_processes.html"},{default:e(()=>t[23]||(t[23]=[o("高斯过程")])),_:1,__:[23]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-loss-functions.html"},{default:e(()=>t[24]||(t[24]=[o("损失函数")])),_:1,__:[24]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-boosting.html"},{default:e(()=>t[25]||(t[25]=[o("提升")])),_:1,__:[25]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-representer-function.html"},{default:e(()=>t[26]||(t[26]=[o("表示函数")])),_:1,__:[26]})]),l("li",null,[n(s,{to:"/posts/CS229/cs229-hoeffding.html"},{default:e(()=>t[27]||(t[27]=[o("Hoeffding不等式")])),_:1,__:[27]})])])])}const g=a(u,[["render",d]]),C=JSON.parse('{"path":"/posts/CS229/CS229ReadingGuide.html","title":"CS229 Reading Guide","lang":"en-US","frontmatter":{"title":"CS229 Reading Guide","description":"CS229 Reading Guide","date":"2025-10-01T00:00:00.000Z","timeline":true,"head":[["meta",{"name":"keywords","content":"CS229 Reading Guide"}],["meta",{"name":"description","content":"CS229 Reading Guide"}],["meta",{"name":"author","content":"Andrew Yan-Tak Ng"}]],"category":["RobinElysia"],"tag":["CS229"]},"headers":[{"level":2,"title":"目录","slug":"目录","link":"#目录","children":[]}],"git":{"updatedTime":1762519389000,"contributors":[{"name":"qwp_p","username":"","email":"qwp20060309@outlook.com","commits":1}],"changelog":[{"hash":"cfd09171d1be97fa09ef8c4fc2be80d788219c63","time":1762519389000,"email":"qwp20060309@outlook.com","author":"qwp_p","message":"Update blog content and add new articles"}]},"filePathRelative":"posts/CS229/CS229ReadingGuide.md","excerpt":"<p><img src=\\"/assets/img/MachineLearning/Voyager3.jpg\\" style=\\"display: block;\\nmargin: 0 auto;\\"></p>\\n<h2>目录</h2>\\n<ul>\\n<li><a href=\\"/posts/CS229/cs229-notes1.html\\" target=\\"_blank\\">第一部分到第三部分</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes2.html\\" target=\\"_blank\\">第四部分 生成学习算法</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes3.html\\" target=\\"_blank\\">第五部分 支持向量机</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes4.html\\" target=\\"_blank\\">第六部分 学习理论</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes5.html\\" target=\\"_blank\\">第七部分 正则化与模型选择</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes6.html\\" target=\\"_blank\\">感知器和大型边界分类器</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes7a.html\\" target=\\"_blank\\">K 均值聚类算法</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes7b.html\\" target=\\"_blank\\">混合高斯和期望最大化算法</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes8.html\\" target=\\"_blank\\">第九部分 期望最大化算法</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes9.html\\" target=\\"_blank\\">第十部分 因子分析</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes10.html\\" target=\\"_blank\\">第十一部分 主成分分析</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes11.html\\" target=\\"_blank\\">第十二部分 独立成分分析</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes12.html\\" target=\\"_blank\\">第十三部分 强化学习和控制</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes13.html\\" target=\\"_blank\\">第十四部分 线性二次调节，微分动态规划，线性二次高斯分布</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-deep_learning.html\\" target=\\"_blank\\">深度学习</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-BP.html\\" target=\\"_blank\\">反向传播</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-dt.html\\" target=\\"_blank\\">决策树</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-ensemble.html\\" target=\\"_blank\\">集成学习</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-cvxopt.html\\" target=\\"_blank\\">凸优化1</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-cvxopt2.html\\" target=\\"_blank\\">凸优化2</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-hmm.html\\" target=\\"_blank\\">隐马尔可夫模型基础</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-gaussians.html\\" target=\\"_blank\\">多元高斯分布</a></li>\\n<li><a href=\\"/posts/CS229/cs229-notes-more_on_gaussians.html\\" target=\\"_blank\\">更多关于多元高斯分布</a></li>\\n<li><a href=\\"/posts/CS229/cs229-gaussian_processes.html\\" target=\\"_blank\\">高斯过程</a></li>\\n<li><a href=\\"/posts/CS229/cs229-loss-functions.html\\" target=\\"_blank\\">损失函数</a></li>\\n<li><a href=\\"/posts/CS229/cs229-boosting.html\\" target=\\"_blank\\">提升</a></li>\\n<li><a href=\\"/posts/CS229/cs229-representer-function.html\\" target=\\"_blank\\">表示函数</a></li>\\n<li><a href=\\"/posts/CS229/cs229-hoeffding.html\\" target=\\"_blank\\">Hoeffding不等式</a></li>\\n</ul>"}');export{g as comp,C as data};
