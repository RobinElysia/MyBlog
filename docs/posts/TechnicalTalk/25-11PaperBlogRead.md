---

title: 十一月：论文、博客、通讯阅读
description: 十一月：论文、博客、通讯阅读
date: 2025-11-01
timeline: true
head:
  - - meta
    - name: keywords
      content: 十一月：论文、博客、通讯阅读
  - - meta
    - name: description
      content: 十一月：论文、博客、通讯阅读
  - - meta
    - name: author
      content: RobinElysia
category:
  - RobinElysia
tag:
  - 技术漫谈
  - 浅读文章

---

<link rel="stylesheet" href="/css/font-style.css">

<img src="/assets/img/MachineLearning/Voyager2.jpg" style="display: block;margin: 0 auto;" />

## Preference

### Paper

### Communications/Blog

&emsp;1. [答案引擎重新定义搜索Answer Engines Redefine Search](https://cacm.acm.org/news/answer-engines-redefine-search/)

> 1. 新型人工智能搜索引擎，也称为答案引擎，利用大型语言模型（LLM）为复杂查询提供直接、对话式的答案，支持多步骤推理，并允许用户以交互方式优化搜索。这一演变使传统搜索从关键词匹配转向能够理解上下文、意图和多模态输入的人工智能系统，并将用户体验从筛选链接转变为与人工智能进行对话。
> 2. 为了应对搜索引擎的冲击，谷歌自身也做出了一些调整。2024年5月，谷歌推出了AI概览（AI Overviews，简称AIOs），这项搜索功能会根据用户的搜索查询生成AI生成的摘要，这些摘要通常会出现在搜索结果页面的最上方，也就是谷歌返回传统搜索结果时，付费最高的广告商所在的位置。
> 3. 出版商正加大力度防止人工智能搜索引擎未经授权使用其内容。这些搜索引擎会聚合和汇总来自出版商网站的大量数据。面对网站流量下降和广告收入减少的困境，出版商采取了法律行动和许可协议，以保护其知识产权并实现其商业价值。与此同时，一些技术措施——例如屏蔽人工智能网络爬虫和使用 TollBit 等人工智能商业化服务——也正在实施，以阻止或规范人工智能对出版商内容的访问。
> 4. 怀特表示：“最终，我们目前正在从搜索引擎向答案引擎演进。下一步是从答案引擎演进到行动引擎。这些实际上是能够代表用户执行整个任务或任务部分内容的代理。”

&emsp;2. [编排：企业人工智能中缺失的一环Orchestration: The Missing Link in Enterprise AI](https://cacm.acm.org/blogcacm/orchestration-the-missing-link-in-enterprise-ai/)

&emsp;3. [技术定义标准Criteria for Technical Definitions](https://cacm.acm.org/blogcacm/criteria-for-technical-definitions/)

> 1. 在任何技术领域，对概念的定义都不应该限制实例必须完美无缺。软件工程的一个特殊之处在于，我们总是倾向于进行道德评判，热衷于告诉人们应该如何工作，有时是为了掩盖我们无法清楚地告诉他们应该做什么的事实。这些要点式表述违反了清晰写作的基本原则，因为它们没有明确指出应该使用并列关系（“和”还是“或”）。数字孪生体必须满足所有这些属性吗？或者只需要满足其中一部分？如果是，那么具体是哪些属性？原则是：定义必须明确无误。

&emsp;4. [笨蛋，是规格说明！It’s the Specification, Stupid!](https://cacm.acm.org/opinion/its-the-specification-stupid/)

> 1. 事实上，目前普遍采用的在低质量软件上层层修补的做法，似乎只会加剧一场徒劳无功的恶性竞争。大型语言模型（LLM）生成的代码可能会使情况变得更糟，因为引导LLM本身就是一门艺术，LLM可能会返回意料之外的、存在缺陷的软件，而且LLM可靠的自检能力目前更多的是一种美好的愿望，而非现实。
> 2. 形式化验证是传统漏洞查找方法之外的一种可行（甚至是唯一）的替代方案。它是一套基于数学的验证技术，旨在支持软件密集型系统的规范化开发。形式化验证与工业软件开发的融合已取得显著进展。尽管取得了这些进展，形式化验证仍未得到广泛应用，理想与实践之间仍然存在巨大差距。
> 3. 然而，验证（无论是形式化验证还是其他形式的验证）目前在生命周期中仍然处于相当靠后的位置。到那时，最严重的设计错误已经出现，而且在规范中发现错误的概率至少与在实现中发现错误的概率一样高。这样一来，验证就好比在大部分马匹已经离开后才锁上谷仓的门，其主要功能也仅限于查找和修复剩余的缺陷，而这些缺陷往往是针对有缺陷的规范进行的。
> 4. 底层程序验证演算通常基于霍尔演算的变体，虽然对于玩具编程语言来说直观且非常优雅，但对于现代软件系统中种类繁多的编程结构和极其复杂的底层状态空间而言，却显得笨拙不堪。对于共享变量并发机制来说，情况尤其如此。鉴于这些限制和复杂性，基于现实世界编程语言的形式化验证有时就像拉着手刹开车一样。更糟糕的是，验证通常针对那些功能嵌入在操作系统、通信总线和中间件等复杂结构中的软件进行。
> 5. “霍尔演算”可能指的是“霍尔逻辑”（Hoare Logic）或“霍尔斯特德复杂性度量”（Halstead complexity measures）。霍尔逻辑是计算机科学中一种形式系统，用于用数学方法证明计算机程序的正确性，由东尼·霍尔提出。霍尔斯特德复杂性度量是另一种度量方法，用来量化软件的复杂程度。
> 6. 大型规范工作包括 WebAssembly、RISC-V 指令集架构和 seL4 虚拟机管理程序的形式化。
> 7. 前置：但这需要我们摒弃冯·诺依曼式程序中占主导地位的“测试-修复-测试”循环，以及这种循环通常难以区分小规模和大规模编程的弊端。不可信的软件不应成为形式化流程的来源，而应成为目标。因此，更优的范式是专注于生命周期早期阶段的设计、保障和验证活动，然后根据大型规范生成正确且具有弹性的技术实现。这种工作重心的转变可以同时释放数个数量级的生产力和重用潜力，并实现极高的弹性和安全性。

&emsp;5. [The Emotional Impact of ChatGPT](https://cacm.acm.org/news/the-emotional-impact-of-chatgpt/)

> 1. 麻省理工学院媒体实验室和OpenAI的研究发现，虽然语音聊天机器人最初比文本聊天机器人更有助于缓解孤独感和依赖性，但当语音机器人被大量使用时，这些优势会逐渐减弱。

&emsp;6. [角色互换：人工智能如何训练人类Role Reversals: How AI Trains Humans](https://cacm.acm.org/news/role-reversals-how-ai-trains-humans/)

> 1. 社会科学家为这种适应过程创造了一个术语：操作性条件反射。当词语、短语或想法能够吸引人们，或者传递出智慧、公平或某种社会价值的信息时，人们就会使用它们。
> 2. 语言学习模型（LLM）将如何改变语言，以及人们的思维和行为方式，尚不完全清楚。然而，研究人员已经发出警告。“人类可能会失去语言多样性，”矢仓说。由此产生的负反馈循环可能导致训练数据多样性降低，并最终导致语言的“核心崩溃”，因为人类和人工智能会不断地相互强化。

&emsp;7. [AI Safety Connect 解决了联合国大会上的一个关键关切AI Safety Connect Addresses a Key Concern at the U.N. General Assembly](https://cacm.acm.org/news/ai-safety-connect-addresses-a-key-concern-at-the-u-n-general-assembly/)

&emsp;8. [通往超人级人工智能数学家的道路The Path to a Superhuman AI Mathematician](https://cacm.acm.org/news/the-path-to-a-superhuman-ai-mathematician/)

> 1. “未来会出现一位超人般的AI数学家吗？”普林斯顿大学理论计算机科学家桑吉夫·阿罗拉教授在9月份举行的第十二届海德堡桂冠论坛上提出了这个问题。那意味着什么？
> 
> 想象一下所有可能的数学定理的集合；人类数学家只证明了其中的一部分。阿罗拉说：“超人人工智能数学家能够证明的定理比人类更多。”。这个想法可以追溯到20世纪初大卫·希尔伯特关于数学自动化的梦想。尽管哥德尔、图灵和丘奇的工作粉碎了这一梦想，但它留下了永恒的遗产：形式化证明验证（形式验证的含义是根据某个或某些形式规范或属性，使用数学的方法证明其正确性或非正确性）的概念——即数学证明可以用精确的语言编写，然后由计算机进行严格的验证。
> 2. 现代开源编程语言和证明辅助工具Lean（Lean 是微软研究院在2013 年推出的计算机定理证明器）非常适合用于此目的。
> 3. 但那些值得探索的数学问题呢？它们还需要人类数学家吗？阿罗拉说：“越来越多的证据表明，人工智能本身就能生成非常好的问题，因此你不再需要人类提供的庞大题库。人工智能或许会从一些人类数据开始，但之后它就能自主生成新的问题。为什么这种方法可行？人工智能最强大的优势在于它的创造力。它基于海量数据进行训练，然后能够从数据中发现信息，并以有趣的方式将它们组合起来。它确实很有创造力，但我们也知道它也会产生幻觉，对吧？它对真理的理解并不十分准确。但它拥有精益求精的能力来验证答案，并剔除错误的问题和答案。”
> 4. Arora 提到了 DeepMind 的 AlphaGeometry 和 AlphaProof，以及他自己在普林斯顿语言与智能实验室开发的哥德尔证明器。2023 年，AlphaGeometry 无需人类演示即可解决国际数学奥林匹克 (IMO) 级别的几何问题。AlphaProof 则专注于更通用的形式数学推理，而不仅仅是几何，并在 2024 年达到了 IMO 银牌标准。今年，OpenAI 和 Google 的模型达到了 IMO 金牌标准。
> 5. 今年早些时候，人工智能初创公司 Morph Labs 宣布其人工智能在将英文证明翻译成 Lean 语言方面取得了重大进展，这为打造超人般的人工智能数学家铺平了道路。数学家陶哲轩和 Alex Kontorovich 一直试图将强素数定理翻译成 Lean 语言，他们原以为这项工作需要数年时间才能完成，但借助名为 Gauss 的人工智能工具，Morph Labs 仅用了三周时间就做到了。
> 6. 但请记住，这种数学超级智能并不意味着它完美无缺，而只是比人类更胜一筹。”